<!DOCTYPE HTML>
<html>
<head>
  <meta charset="utf-8" />
  
  <title>Seite 7 | YBC HomePage</title>
  <meta name="author" content="BaiChuan Yang" />

  
  <meta name="description" content="Blog mainly about IT technology and Interesting Life Events~" />
  

  

  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />

  
  <meta property="og:site_name" content="YBC HomePage" />

  <meta name="google-site-verification" content="IK-tjIwORWUinhhD-XZkyX5FWQgd568VBgmJorjK7Bg" />
  
  <meta name="msvalidate.01" content="E6F8036020E5423AA7576A75B806937B" />  

  
    <meta property="og:image" content="undefined" />
  

  
  <link href="/css/images/favicon.ico" rel="icon" />
  

  <link rel="alternate" href="/atom.xml" title="YBC HomePage" type="application/atom+xml">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
  
<script>
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
		(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
			m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

	ga('create', 'UA-63602183-1', 'auto');
	ga('send', 'pageview');

</script>



  <!-- baidu webmaster push -->
  <script src='//push.zhanzhang.baidu.com/push.js'></script>
</head>


<body>
  <header id="header" class="inner"><div class="alignleft">
  <h1><a href="/">YBC HomePage</a></h1>
  <h2><a href="/">Study~ Work~ Life~ Everything is here~</a></h2>
</div>
<nav id="main-nav" class="alignright">
  <ul>
    
      <li><a href="/">Home</a></li>
    
      <li><a href="/archives">Archives</a></li>
    
      <li><a href="/about">About</a></li>
    
      <li><a href="/atom.xml">RSS</a></li>
    
      <li><a href="/sitemap.xml">SiteMap</a></li>
    
  </ul>
  <div class="clearfix"></div>
</nav>
<script type="text/javascript">
  (function(w,d,t,u,n,s,e){w['SwiftypeObject']=n;w[n]=w[n]||function(){
  (w[n].q=w[n].q||[]).push(arguments);};s=d.createElement(t);
  e=d.getElementsByTagName(t)[0];s.async=1;s.src=u;e.parentNode.insertBefore(s,e);
  })(window,document,'script','//s.swiftypecdn.com/install/v2/st.js','_st');
  
  _st('install','xeEkJ65dmswemsvZM1Nx','2.0.0');
</script>
<div class="clearfix"></div>
</header>
  <div id="content" class="inner">
    <div id="main-col" class="alignleft"><div id="wrapper">
  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2015-09-06T08:25:50.000Z"><a href="/2015/09/06/Mahout-Install-and-Basic-Commands/">2015-09-06</a></time>
      
      
  
    <h1 class="title"><a href="/2015/09/06/Mahout-Install-and-Basic-Commands/">Mahout Install and Basic Commands</a></h1>
  

    </header>
    <div class="entry">
      
      
        <p>Here is a simple tutorial for Mahout installation and summary of its basic commands.</p>
<h3 id="Mahout-Installation"><a href="#Mahout-Installation" class="headerlink" title="Mahout Installation"></a>Mahout Installation</h3><p>At first, we should install a Hadoop system on the machine and here are the tutorials of Single Node Hadoop Setup Guide:<a href="http://yular.github.io/2015/09/01/Hadoop-1.x-Single-Node-Cluster-Step-Up-Guide/">Hadoop 1.x</a> and <a href="http://yular.github.io/2015/09/02/Hadoop-2-x-Single-Node-Cluster-Step-Up-Guide/">Hadoop 2.x</a>.</p>
<p>Then we can download Mahout from <a href="https://mahout.apache.org/general/downloads.html" target="_blank" rel="external">official website</a> or from <a href="https://github.com/apache/mahout" target="_blank" rel="external">Github</a>. We can download the pre-built jar or source code. </p>
<p>To install Mahout source code project, run these commands:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tar -xzvf mahout-version.tar.gz <span class="comment">#Optional but needed if we download the tarball</span></span><br><span class="line"><span class="built_in">cd</span> mahout</span><br><span class="line">mvn clean</span><br><span class="line">mvn install -DskipTests</span><br></pre></td></tr></table></figure></p>
<p>The compile and package process will cost some time but it will be faster if we skip tests when run “mvn install”. If no errors occur, it means the Mahout project has been built successfully and workable now.</p>

      
    </div>
    
    <footer>
        <div class="alignright">
          
          <a href='javascript:void(0)' class="share-link bdsharebuttonbox" data-cmd="more">Share</a>
        </div>
        
        
  
  <div class="tags">
    <a href="/tags/Cloud-Computing/">Cloud Computing</a>
  </div>

        <!-- partial('post/share') -->
      <div class="clearfix"></div>
    </footer>
  </div>
</article>






  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2015-09-05T06:37:57.000Z"><a href="/2015/09/04/Kafka-Install-and-Basic-Commands/">2015-09-04</a></time>
      
      
  
    <h1 class="title"><a href="/2015/09/04/Kafka-Install-and-Basic-Commands/">Kafka Install and Basic Commands</a></h1>
  

    </header>
    <div class="entry">
      
      
        <p>Here is the official website of <a href="http://kafka.apache.org/" target="_blank" rel="external">Kafka</a>.</p>
<p>###KafKa Install<br>Here is the official document of <a href="http://kafka.apache.org/documentation.html#quickstart" target="_blank" rel="external">Kafka Install</a>.</p>
<p>Now the following is the guide of kafka installation:</p>
<p>#####Download and Un-tar Kafka<br><a href="http://kafka.apache.org/documentation.html#quickstart" target="_blank" rel="external">click here</a> to download Kafka.</p>
<p>Run this command to un-tar Kafka<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tar -xzf kafka_[version code].tgz</span><br><span class="line"><span class="built_in">cd</span> kafka_[version code]</span><br></pre></td></tr></table></figure></p>
<p>Now the stand-alone mode of Kafka is setup.</p>
<p>###Start Kafka Server<br>Kafka uses ZooKeeper so we need to first start a ZooKeeper server. If we do not have one, run the following scripts under Kafka project to get a quick-and-dirty single-node ZooKeeper instance.<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/zookeeper-server-start.sh config/zookeeper.properties</span><br></pre></td></tr></table></figure></p>
<p>If we have already installed a Zookeeper instance, check the <a href="http://yular.github.io/2015/09/03/Zookeeper-Install-and-Basic-Commands/">this link</a> to see how to start it.</p>
<p>After ZooKeeper is boost, open a new terminal tab/window and run this script:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-server-start.sh config/server.properties</span><br></pre></td></tr></table></figure></p>
<p>Note that if Kafa fails to start because it cannot create the log directory, do these steps:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">vi config/server.properties <span class="comment"># See what is the value of log.dir item; initially it should be /var/kafka-logs and let us modify it as /tmp/kafka-log</span></span><br><span class="line"><span class="built_in">cd</span> /tmp</span><br><span class="line">sudo mkdir kafka-logs</span><br><span class="line">sudo chmod 777 kafka-logs</span><br></pre></td></tr></table></figure></p>
<p>Now the Kafka cluster is running.</p>
<hr>

<p>###Kafka Basic Example<br>When Kafka server is running, follow these steps to run a simple example.</p>
<p>At first, open a new terminal tab/window and then create a topic named “test”:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic <span class="built_in">test</span></span><br></pre></td></tr></table></figure></p>
<p>And we can run this script to list all existing topics:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-topics.sh --list --zookeeper localhost:2181</span><br></pre></td></tr></table></figure></p>
<p>If the topic is generated successfully, then start a publisher to send some message:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-console-producer.sh --broker-list localhost:9092 --topic <span class="built_in">test</span></span><br></pre></td></tr></table></figure></p>
<p>Note: The topic name should be correct.</p>
<p>Now open a new terminal tab/window to start a consumer to receive the messages:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic <span class="built_in">test</span> --from-beginning</span><br></pre></td></tr></table></figure></p>
<p>Note: The topic name should be correct.</p>
<p>Now if we type message on publisher end and send it, then in the consumer end, we will see the message in a short time:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># publisher</span></span><br><span class="line">haha</span><br><span class="line">hoho</span><br><span class="line">hehe</span><br><span class="line"></span><br><span class="line"><span class="comment"># consumer</span></span><br><span class="line">haha</span><br><span class="line">hoho</span><br><span class="line">hehe</span><br></pre></td></tr></table></figure></p>

      
    </div>
    
    <footer>
        <div class="alignright">
          
          <a href='javascript:void(0)' class="share-link bdsharebuttonbox" data-cmd="more">Share</a>
        </div>
        
        
  
  <div class="tags">
    <a href="/tags/Cloud-Computing/">Cloud Computing</a>
  </div>

        <!-- partial('post/share') -->
      <div class="clearfix"></div>
    </footer>
  </div>
</article>






  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2015-09-05T06:37:17.000Z"><a href="/2015/09/04/Spark-Install-and-Basic-Commands/">2015-09-04</a></time>
      
      
  
    <h1 class="title"><a href="/2015/09/04/Spark-Install-and-Basic-Commands/">Spark Install and Basic Commands</a></h1>
  

    </header>
    <div class="entry">
      
      
        <p>Here is the tutorial of installing Apache Spark on Linux System.</p>
<h3 id="Install-Scala"><a href="#Install-Scala" class="headerlink" title="Install Scala"></a>Install Scala</h3><p>Go to Scala official website to <a href="http://www.scala-lang.org/files/archive/" target="_blank" rel="external">download binary file</a>. Or use following command:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget http://www.scala-lang.org/files/archive/scala-2.11.7.tgz</span><br></pre></td></tr></table></figure></p>
<p>Note that the version can be changed as we like.</p>
<p>Then decompress the tar file and save it under the directory we want:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tar xvf scala-2.11.7.tgz</span><br><span class="line">sudo mv scala-2.11.7 /usr/lib</span><br><span class="line">sudo ln <span class="_">-s</span> /usr/lib/scala-2.11.7 /usr/lib/scala</span><br></pre></td></tr></table></figure></p>
<p>Now edit our .bashrc file under Home directory:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:/usr/lib/scala/bin</span><br></pre></td></tr></table></figure></p>
<p>At last, test whether scala command works in our environment:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">source</span> ~/.bashrc</span><br><span class="line">scala -version</span><br><span class="line"><span class="comment"># The output should look like:</span></span><br><span class="line"><span class="comment"># Scala code runner version 2.11.7 -- Copyright 2002-2013, LAMP/EPFL</span></span><br></pre></td></tr></table></figure></p>
<h3 id="Install-Spark"><a href="#Install-Spark" class="headerlink" title="Install Spark"></a>Install Spark</h3><p>Go to Spark Official Website to <a href="http://spark.apache.org/docs/latest/" target="_blank" rel="external">download Spark</a>. In this tutorial, we download a pre-built version.</p>
<p>Then decompress the package.<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar xvzf spark-version.tgz</span><br></pre></td></tr></table></figure></p>
<p>After that we can move the project directory to the file path which we prefer.</p>
<p>Now we can go to the Spark project directory and start the standalone master by executing:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./sbin/start-master.sh</span><br></pre></td></tr></table></figure></p>
<p>By default, master’s web UI is <a href="http://localhost:8080" target="_blank" rel="external">http://localhost:8080</a>.</p>
<p>To stop the cluster, execute this command:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./sbin/stop-master.sh</span><br></pre></td></tr></table></figure></p>

      
    </div>
    
    <footer>
        <div class="alignright">
          
          <a href='javascript:void(0)' class="share-link bdsharebuttonbox" data-cmd="more">Share</a>
        </div>
        
        
  
  <div class="tags">
    <a href="/tags/Cloud-Computing/">Cloud Computing</a>
  </div>

        <!-- partial('post/share') -->
      <div class="clearfix"></div>
    </footer>
  </div>
</article>






  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2015-09-05T06:37:04.000Z"><a href="/2015/09/04/Storm-Install-and-Basic-Commands/">2015-09-04</a></time>
      
      
  
    <h1 class="title"><a href="/2015/09/04/Storm-Install-and-Basic-Commands/">Storm Install and Basic Commands</a></h1>
  

    </header>
    <div class="entry">
      
      
        
      
    </div>
    
    <footer>
        <div class="alignright">
          
          <a href='javascript:void(0)' class="share-link bdsharebuttonbox" data-cmd="more">Share</a>
        </div>
        
        
  
  <div class="tags">
    <a href="/tags/Cloud-Computing/">Cloud Computing</a>
  </div>

        <!-- partial('post/share') -->
      <div class="clearfix"></div>
    </footer>
  </div>
</article>






  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2015-09-04T03:30:53.000Z"><a href="/2015/09/03/Hadoop-1.x-Basic-Commands/">2015-09-03</a></time>
      
      
  
    <h1 class="title"><a href="/2015/09/03/Hadoop-1.x-Basic-Commands/">Hadoop Basic Commands</a></h1>
  

    </header>
    <div class="entry">
      
      
        <p>Here is the link of official hadoop command document. <a href="http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-common/CommandsManual.html#Overview" target="_blank" rel="external">Hadoop Command Official Document</a></p>
<h3 id="Hadoop-DistCp-Command"><a href="#Hadoop-DistCp-Command" class="headerlink" title="Hadoop DistCp Command"></a>Hadoop DistCp Command</h3><p>This kind of command is used for large inter/intra-cluster copying.<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ bin/hadoop distcp &lt;<span class="built_in">source</span> uri&gt; &lt;dest uri&gt;</span><br></pre></td></tr></table></figure></p>
<hr>

<h3 id="Hadoop-FileSystem-Command"><a href="#Hadoop-FileSystem-Command" class="headerlink" title="Hadoop FileSystem Command"></a>Hadoop FileSystem Command</h3><p>Append single src, or multiple srcs from local file system to the destination file system. Also reads input from stdin and appends to destination file system.<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ bin/hadoop fs -appendToFile src[src ...] dst</span><br></pre></td></tr></table></figure></p>
<p>Print out the content of a specific file in HDFS<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ bin/hadoop fs -cat URI[URI ...]</span><br></pre></td></tr></table></figure></p>
<p>Returns the checksum information of a file.<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ bin/hadoop fs -checksum URI</span><br></pre></td></tr></table></figure></p>
<p>Change the permissions of files.<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ bin/hadoop fs -chmod [-R] &lt;MODE[,MODE]... | OCTALMODE&gt; URI[URI ...]</span><br></pre></td></tr></table></figure></p>
<p>Change the owner of files.<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ bin/hadoop fs -chown [-R] [OWNER][:[GROUP]] URI [URI ]</span><br></pre></td></tr></table></figure></p>
<p>Copy files from source to destination.<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ bin/hadopp fs -cp [<span class="_">-f</span>] [-p | -p[topax]] URI [URI ...] &lt;dest&gt;</span><br></pre></td></tr></table></figure></p>
<p>Finds all files that match the specified expression and applies selected actions to them.<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ bin/hadoop fs -find &lt;path&gt; ... &lt;expression&gt; ...</span><br></pre></td></tr></table></figure></p>
<p>Copy local files to HDFS. Similar to put command, except that the source is restricted to a local file reference.<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ bin/hadoop fs -copyFromLocal &lt;localsrc&gt; URI</span><br></pre></td></tr></table></figure></p>
<p>Copy files to the local file system. Files that fail the CRC check may be copied with the -ignorecrc option. Files and CRCs may be copied using the -crc option.<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ bin/hadoop fs -get [-ignorecrc] [-crc] &lt;src&gt; &lt;localdst&gt;</span><br></pre></td></tr></table></figure></p>
<p>Copy files from HDS to local. Similar to get command, except that the destination is restricted to a local file reference.<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ bin/hadoop fs -copyToLocal [-ignorecrc] [-crc] URI &lt;localdst&gt;</span><br></pre></td></tr></table></figure></p>
<p>Get usage output<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ bin/hadoop <span class="built_in">help</span></span><br></pre></td></tr></table></figure></p>
<p>Returns the state of file or children under directory<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ bin/hadoop fs -ls [<span class="_">-d</span>] [-h] [-R] [-t] [-S] [-r] [-u] &lt;args&gt;</span><br></pre></td></tr></table></figure></p>
<p>Takes path uri’s as argument and creates directories.<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ bin/hadoop fs -mkdir [-p] &lt;paths&gt;</span><br></pre></td></tr></table></figure></p>
<p>Move files from local to HDFS. Similar to put command, except that the source localsrc is deleted after it’s copied.<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ bin/hadoop fs -moveFromLocal &lt;localsrc&gt; &lt;dst&gt;</span><br></pre></td></tr></table></figure></p>
<p>Move files from HDFS to local.<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ bin/hadoop fs -moveToLocal [-crc] &lt;src&gt; &lt;dst&gt;</span><br></pre></td></tr></table></figure></p>
<p>Move files from source to destination.<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ bin/hadoop fs -mv URI [URI ...] &lt;dest&gt;</span><br></pre></td></tr></table></figure></p>
<p>Copy single src, or multiple srcs from local file system to the destination file system. Also reads input from stdin and writes to destination file system.<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ bin/hadoop fs -put &lt;localsrc&gt; ... &lt;dst&gt;</span><br></pre></td></tr></table></figure></p>
<p>Delete files specified as args.<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ bin/hadoop fs -rm [<span class="_">-f</span>] [-r |-R] [-skipTrash] URI [URI ...]</span><br></pre></td></tr></table></figure></p>
<p>Delete a directory.<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ bin/hadoop fs -rmdir [--ignore-fail-on-non-empty] URI [URI ...]</span><br></pre></td></tr></table></figure></p>
<p>Recursive version of delete.<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ bin/hadoop fs -rmr [-skipTrash] URI [URI ...]</span><br></pre></td></tr></table></figure></p>
<p>Print statistics about the file/directory at <path></path> in the specified format. Format accepts filesize in blocks (%b), type (%F), group name of owner (%g), name (%n), block size (%o), replication (%r), user name of owner(%u), and modification date (%y, %Y). %y shows UTC date as “yyyy-MM-dd HH:mm:ss” and %Y shows milliseconds since January 1, 1970 UTC. If the format is not specified, %y is used by default.<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ bin/hadoop fs -stat [format] &lt;path&gt; ...</span><br></pre></td></tr></table></figure></p>
<p>Displays last kilobyte of the file to stdout.<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ bin/hadoop fs -tail [<span class="_">-f</span>] URI</span><br></pre></td></tr></table></figure></p>
<p>Takes a source file and outputs the file in text format.<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ bin/hadoop fs -text &lt;src&gt;</span><br></pre></td></tr></table></figure></p>
<p>Truncate all files that match the specified file pattern to the specified length.<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ bin/hadoop fs -truncate [-w] &lt;length&gt; &lt;paths&gt;</span><br></pre></td></tr></table></figure></p>
<hr>

<h3 id="Runs-jar-files"><a href="#Runs-jar-files" class="headerlink" title="Runs jar files"></a>Runs jar files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ bin/hadoop jar &lt;jar&gt; [mainClass] args...</span><br></pre></td></tr></table></figure>
<hr>

<h3 id="Hadoop-Version-Command"><a href="#Hadoop-Version-Command" class="headerlink" title="Hadoop Version Command"></a>Hadoop Version Command</h3><p>Prints the version of Hadoop system<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ bin/hadoop version</span><br></pre></td></tr></table></figure></p>
<hr>

<h3 id="Hadoop-CLASSNAME"><a href="#Hadoop-CLASSNAME" class="headerlink" title="Hadoop CLASSNAME"></a>Hadoop CLASSNAME</h3><p>Runs the class named CLASSNAME<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ bin/hadoop CLASSNAME</span><br></pre></td></tr></table></figure></p>

      
    </div>
    
    <footer>
        <div class="alignright">
          
          <a href='javascript:void(0)' class="share-link bdsharebuttonbox" data-cmd="more">Share</a>
        </div>
        
        
  
  <div class="tags">
    <a href="/tags/Cloud-Computing/">Cloud Computing</a>
  </div>

        <!-- partial('post/share') -->
      <div class="clearfix"></div>
    </footer>
  </div>
</article>






  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2015-09-04T03:29:42.000Z"><a href="/2015/09/03/Pig-Install-and-Basic-Commands/">2015-09-03</a></time>
      
      
  
    <h1 class="title"><a href="/2015/09/03/Pig-Install-and-Basic-Commands/">Pig Install and Basic Commands</a></h1>
  

    </header>
    <div class="entry">
      
      
        <p>Here is the official website of <a href="https://pig.apache.org/" target="_blank" rel="external">Apache Pig</a>. The following is the tutorial of pig installation and summary of basic commands.</p>
<h3 id="Pig-Intallation"><a href="#Pig-Intallation" class="headerlink" title="Pig Intallation"></a>Pig Intallation</h3><p>Download the pig from this <a href="https://pig.apache.org/releases.html#Download" target="_blank" rel="external">link</a>. Just choose any one release. In this tutorial, we use Pig-0.14.0.</p>
<p>Then unpacked the distribution using these commands:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tar -xzvf pig-0.14.0.tar.gz</span><br><span class="line">mv pig-0.14.0 <span class="string">"the directory you would like to install pig"</span></span><br></pre></td></tr></table></figure></p>
<p>Add pig-0.14.0/bin to environment path.<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">vi ~/.bashrc</span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="string">"path to pig project directory"</span>/bin</span><br></pre></td></tr></table></figure></p>
<p>Quit vim editor and “source” your .bashrc file.</p>
<p>Run this command to test whether pig works or not:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pig -help</span><br></pre></td></tr></table></figure></p>
<h3 id="Running-Pig"><a href="#Running-Pig" class="headerlink" title="Running Pig"></a>Running Pig</h3><p>Pig can be run in two modes, namely Local Mode and Mapreduce Mode.<br>In local mode, we can access to a single machine and all files are installed and run using your local host and file system.<br>In mapreduce mode, we can access to a Hadoop cluster and HDFS installation and this mode is the default mode. In this mode, it is required that Hadoop and HDFS should be running.</p>
<p>To run pig in local, using this command:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pig -x <span class="built_in">local</span></span><br><span class="line"><span class="comment"># or</span></span><br><span class="line">java -cp pig.jar org.apache.pig.Main -x <span class="built_in">local</span> <span class="comment">#java command</span></span><br></pre></td></tr></table></figure></p>
<p>To run pig in mapreduce mode, using this command:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">pig</span><br><span class="line"><span class="comment"># or</span></span><br><span class="line">pig -x mapreduce</span><br><span class="line"><span class="comment"># or</span></span><br><span class="line">java -cp pig.jar org.apache.pig.Main  <span class="comment">#java command</span></span><br><span class="line"><span class="comment"># or</span></span><br><span class="line">java -cp pig.jar org.apache.pig.Main -x mapreduce <span class="comment">#java command</span></span><br></pre></td></tr></table></figure></p>
<p>Moreover, we can run pig in interactive mode using the Grunt shell through this command:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pig</span><br></pre></td></tr></table></figure></p>
<p>and then enter Pig Latin statements and Pig commands interactively at the command line.</p>

      
    </div>
    
    <footer>
        <div class="alignright">
          
          <a href='javascript:void(0)' class="share-link bdsharebuttonbox" data-cmd="more">Share</a>
        </div>
        
        
  
  <div class="tags">
    <a href="/tags/Cloud-Computing/">Cloud Computing</a>
  </div>

        <!-- partial('post/share') -->
      <div class="clearfix"></div>
    </footer>
  </div>
</article>






  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2015-09-04T02:54:03.000Z"><a href="/2015/09/03/Zookeeper-Install-and-Basic-Commands/">2015-09-03</a></time>
      
      
  
    <h1 class="title"><a href="/2015/09/03/Zookeeper-Install-and-Basic-Commands/">Zookeeper Install and Basic Commands</a></h1>
  

    </header>
    <div class="entry">
      
      
        <p>Here is a simple tutorial of Zookeeper installation and a summary of its basic commands. Note that if we do not use root account, we may have to use “sudo” command to execute some commands or grant read, write or execution access to the account we use.</p>
<h3 id="Zookeeper-Installation"><a href="#Zookeeper-Installation" class="headerlink" title="Zookeeper Installation"></a>Zookeeper Installation</h3><p>Here is the link of official <a href="https://zookeeper.apache.org/doc/r3.1.2/zookeeperStarted.html" target="_blank" rel="external">tutorial</a>. The following is my tutorial.</p>
<p>Environment: Ubuntu 14.04<br>Zookeeper: zookeeper 3.4.6</p>
<h5 id="Downlaod-and-Unpack-Zookeeper"><a href="#Downlaod-and-Unpack-Zookeeper" class="headerlink" title="Downlaod and Unpack Zookeeper"></a>Downlaod and Unpack Zookeeper</h5><p>Here is the link to download <a href="http://zookeeper.apache.org/releases.html" target="_blank" rel="external">stable release</a> of zookeeper.</p>
<p>Then unpack the tar.gz file:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tar -zxvf zookeeper-x.x.x.tar.gz</span><br></pre></td></tr></table></figure></p>
<p>After that, move the project directory to location we want.</p>
<h5 id="Edit-configuration-file"><a href="#Edit-configuration-file" class="headerlink" title="Edit configuration file"></a>Edit configuration file</h5><p>Go to zookeeper project directory and create a configure file using this command:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">vi conf/zoo.cfg</span><br></pre></td></tr></table></figure></p>
<p>Note that we may find zoo_sample.cfg file instead. In this case, we should change the name of that file to zoo.cfg.</p>
<p>And add following content into that file:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tickTime=2000 <span class="comment">#It is used to do heartbeats and the minimum session timeout will be twice the tickTime. The basic unit is milliseconds.</span></span><br><span class="line">dataDir=/var/zookeeper <span class="comment">#Here is the directory where zookeeper save its data.</span></span><br><span class="line">clientPort=2181 <span class="comment">#The port to listen for client connections.</span></span><br></pre></td></tr></table></figure></p>
<p>Note that we can create /va/zookeeper directory and change the read, write and execution access before we start the server.</p>
<p>Now we have successfully setted up a Zookeeper server in standalone mode.</p>
<h5 id="Start-Restart-Stop-and-Connect-to-the-server"><a href="#Start-Restart-Stop-and-Connect-to-the-server" class="headerlink" title="Start, Restart, Stop and Connect to the server"></a>Start, Restart, Stop and Connect to the server</h5><p>The command to start the server:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/zkServer.sh start</span><br></pre></td></tr></table></figure></p>
<p>To test whether the server is working or not, use this command:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">jps</span><br></pre></td></tr></table></figure></p>
<p>And we should see a similar output like this:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">6834 JPS</span><br><span class="line">6997 QuorumPeerMain</span><br></pre></td></tr></table></figure></p>
<p>The command to restart the server:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/zkServer.sh restart</span><br></pre></td></tr></table></figure></p>
<p>The command to stop the server:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bin/zkServer.sh stop</span><br></pre></td></tr></table></figure></p>
<p>The command to connect to the server:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Java</span></span><br><span class="line">bin/zkCli.sh 127.0.0.1:2181</span><br><span class="line"></span><br><span class="line"><span class="comment">#C/C++</span></span><br><span class="line">LD_LIBRARY_PATH=. cli_mt 127.0.0.1:2181</span><br><span class="line"><span class="comment">#or</span></span><br><span class="line">LD_LIBRARY_PATH=. cli_st 127.0.0.1:2181</span><br></pre></td></tr></table></figure></p>

      
    </div>
    
    <footer>
        <div class="alignright">
          
          <a href='javascript:void(0)' class="share-link bdsharebuttonbox" data-cmd="more">Share</a>
        </div>
        
        
  
  <div class="tags">
    <a href="/tags/Cloud-Computing/">Cloud Computing</a>
  </div>

        <!-- partial('post/share') -->
      <div class="clearfix"></div>
    </footer>
  </div>
</article>






  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2015-09-04T02:53:52.000Z"><a href="/2015/09/03/Hbase-Install-and-Basic-Commands/">2015-09-03</a></time>
      
      
  
    <h1 class="title"><a href="/2015/09/03/Hbase-Install-and-Basic-Commands/">Hbase Install and Basic Commands</a></h1>
  

    </header>
    <div class="entry">
      
      
        
      
    </div>
    
    <footer>
        <div class="alignright">
          
          <a href='javascript:void(0)' class="share-link bdsharebuttonbox" data-cmd="more">Share</a>
        </div>
        
        
  
  <div class="tags">
    <a href="/tags/Cloud-Computing/">Cloud Computing</a>
  </div>

        <!-- partial('post/share') -->
      <div class="clearfix"></div>
    </footer>
  </div>
</article>






  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2015-09-04T02:53:43.000Z"><a href="/2015/09/03/Hive-Install-and-Basic-Commands/">2015-09-03</a></time>
      
      
  
    <h1 class="title"><a href="/2015/09/03/Hive-Install-and-Basic-Commands/">Hive Install and Basic Commands</a></h1>
  

    </header>
    <div class="entry">
      
      
        <p>Here is the official website of <a href="https://cwiki.apache.org/confluence/display/Hive/Home" target="_blank" rel="external">Hive</a>.</p>
<p>###Hive Install<br>Here is the official document of <a href="https://cwiki.apache.org/confluence/display/Hive/GettingStarted" target="_blank" rel="external">Hive Installation</a>.</p>
<p>Now the following is the guide of Hive installation.</p>
<p>#####Uncompress hive package<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ tar -xzvf hive-x.y.z.tar.gz</span><br></pre></td></tr></table></figure></p>
<p>#####Set Hive environment variable<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ vi ~/.bashrc</span><br><span class="line">$ <span class="built_in">export</span> HIVE_HOME=<span class="string">'The absolute path of hive home directory'</span></span><br><span class="line">$ <span class="built_in">export</span> PATH=<span class="variable">$HIVE_HOME</span>/bin:<span class="variable">$PATH</span></span><br></pre></td></tr></table></figure></p>
<hr>



      
    </div>
    
    <footer>
        <div class="alignright">
          
          <a href='javascript:void(0)' class="share-link bdsharebuttonbox" data-cmd="more">Share</a>
        </div>
        
        
  
  <div class="tags">
    <a href="/tags/Cloud-Computing/">Cloud Computing</a>
  </div>

        <!-- partial('post/share') -->
      <div class="clearfix"></div>
    </footer>
  </div>
</article>






  <article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2015-09-03T03:28:44.000Z"><a href="/2015/09/02/Hadoop-2-x-Single-Node-Cluster-Step-Up-Guide/">2015-09-02</a></time>
      
      
  
    <h1 class="title"><a href="/2015/09/02/Hadoop-2-x-Single-Node-Cluster-Step-Up-Guide/">Hadoop 2.x Single-Node Cluster Set Up Guide</a></h1>
  

    </header>
    <div class="entry">
      
      
        <p>Now the following is a lazy set up guide for those who only would like to set up a single-node cluster for some easy tasks, like school homework. This guide should be much quicker than the one recommended above.</p>
<p>Here is a good and more detailed <a href="http://bigdatahandler.com/hadoop-hdfs/installing-single-node-hadoop-2-2-0-on-ubuntu/" target="_blank" rel="external">tutorial</a> from Horton. But they missed an important step which may bring some trouble for beginners.</p>
<p>Environment: Ubuntu 14.04 LTS<br>Hadoop: 2.7.1</p>
<hr>

<p>#####Java Installation<br>Hadoop requires Java 1.5+ installation. So just go to Oracle Java home page to download JDK 1.6 or higher. Here is the link to download Java: <a href="http://www.oracle.com/technetwork/articles/javase/index-jsp-138363.html" target="_blank" rel="external">Java Download</a>. Or we can just the following commands:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt-get install openjdk-7-jdk</span><br></pre></td></tr></table></figure></p>
<p>Here is a tutorial <a href="https://www.digitalocean.com/community/tutorials/how-to-install-java-on-ubuntu-with-apt-get" target="_blank" rel="external">Java Install</a>.</p>
<hr>

<p>#####(Optional)Adding a Hadoop system user<br>Use the following commands to add a new user and a new group for Hadoop system.<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ sudo addgroup hadoop</span><br><span class="line">$ sudo adduser --ingroup hadoop newuser</span><br></pre></td></tr></table></figure></p>
<p>Actually, we can use the existing user and group. If so, just skip this step.</p>
<hr>

<p>#####SSH key<br>Here are the commands to install ssh if our machine does not have one.<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt-get install ssh</span><br><span class="line">$ sudo apt-get install rsync</span><br></pre></td></tr></table></figure></p>
<p>After that, generate SSH key for the user:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ su - newuser</span><br><span class="line">$ ssh-keygen -t rsa -P <span class="string">""</span></span><br><span class="line">$ cat <span class="variable">$HOME</span>/.ssh/id_rsa.pub &gt;&gt; <span class="variable">$GINE</span>/.ssh/authorized_keys</span><br></pre></td></tr></table></figure></p>
<p>Then, do the ssh connection:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ssh localhost</span><br></pre></td></tr></table></figure></p>
<hr>

<p>#####(Optional)Disabling IPv6<br>Just go to the Hadoop setup tutorial provided in the begining.</p>
<hr>

<p>#####Hadoop Download and Installation<br>Go to <a href="http://hadoop.apache.org/releases.html" target="_blank" rel="external">Apache Hadoop Homepage</a> to download the Hadoop from one of the mirrors. Then we can put the Hadoop package to a location of our machine. The location can be /usr/local or even our home directory. Here I choose /usr/local.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /usr/<span class="built_in">local</span></span><br><span class="line">$ sudo tar xzvf hadoop-2.7.1.tar.gz</span><br><span class="line">$ sudo mv hadoop-2.7.1 hadoop</span><br><span class="line">$ sudo chown -R newuser:hadoop hadoop</span><br></pre></td></tr></table></figure>
<p>Now a single-node hadoop is available and if we type command:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hadoop/bin/hadoop</span><br></pre></td></tr></table></figure>
<p>A list of information about “hadoop” command will appear.</p>
<hr>

<p>#####Update Environment Variable<br>Editing the .bashrc file under the home directory of Hadoop system user. Adding these two lines to that file:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> HADOOP_PREFIX=/usr/<span class="built_in">local</span>/hadoop</span><br><span class="line"><span class="built_in">export</span> HADOOP_HOME=/usr/<span class="built_in">local</span>/hadoop</span><br><span class="line"><span class="built_in">export</span> HADOOP_MAPRED_HOME=<span class="variable">$&#123;HADOOP_HOME&#125;</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_COMMON_HOME=<span class="variable">$&#123;HADOOP_HOME&#125;</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_HDFS_HOME=<span class="variable">$&#123;HADOOP_HOME&#125;</span></span><br><span class="line"><span class="built_in">export</span> YARN_HOME=<span class="variable">$&#123;HADOOP_HOME&#125;</span></span><br><span class="line"><span class="built_in">export</span> HADOOP_CONF_DIR=<span class="variable">$&#123;HADOOP_HOME&#125;</span>/etc/hadoop</span><br><span class="line"><span class="built_in">export</span> HADOOP_COMMON_LIB_NATIVE_DIR=<span class="variable">$&#123;HADOOP_PREFIX&#125;</span>/lib/native</span><br><span class="line"><span class="built_in">export</span> HADOOP_OPTS=<span class="string">"-Djava.library.path=<span class="variable">$HADOOP_PREFIX</span>/lib"</span></span><br><span class="line"><span class="built_in">export</span> JAVA_HOME=<span class="string">"the path to your java jdk directory"</span></span><br><span class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$HADOOP_HOME</span>/bin:<span class="variable">$JAVA_HOME</span>/bin:<span class="variable">$HADOOP_HOME</span>/sbin</span><br></pre></td></tr></table></figure></p>
<p>In fact, in Hadoop-1.2.1, HADOOP_HOME variable is deprecated and we can skip this step to set it. If have difficulty to find where the jdk is, this link may be helpful: <a href="http://stackoverflow.com/questions/5251323/where-can-i-find-the-java-sdk-in-linux" target="_blank" rel="external">JDK path</a>.</p>
<hr>

<p>#####Hadoop Distributed File System (HDFS)<br>At first, edit etc/hadoop/hadoop-env.sh file, by setting the JAVA_HOME and HADOOP_CONF_DIR variables:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">export</span> JAVA_HOME=.... (your jdk path)</span><br><span class="line">$ <span class="built_in">export</span> HADOOP_CONF_DIR=/usr/<span class="built_in">local</span>/hadoop/etc/hadoop</span><br></pre></td></tr></table></figure></p>
<p>Note: If we forget to change the HADOOP_CONF_DIR variable, when we start HADOOP YARN system, an “Error: Can not find configuration directory: etc/hadoop” exception will appear. </p>
<p>Then create the two directories for Namenode and Datanode respectively and set the required ownerships as well as permissions:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">$ <span class="built_in">cd</span> /</span><br><span class="line">$ sudo mkdir -p <span class="variable">$HADOOP_HOME</span>/yarn_data/hdfs/namenode</span><br><span class="line">$ sudo chown newuser:hadoop <span class="variable">$HADOOP_HOME</span>/yarn_data/hdfs/namenode</span><br><span class="line">$ sudo mkdir -p <span class="variable">$HADOOP_HOME</span>/yarn_data/hdfs/datanode</span><br><span class="line">$ sudo chown newuser:hadoop <span class="variable">$HADOOP_HOME</span>/yarn_data/hdfs/datanode</span><br><span class="line"><span class="comment"># ...and if you want to tighten up security, chmod from 755 to 750...</span></span><br><span class="line">$ sudo chmod 750 <span class="variable">$HADOOP_HOME</span>/yarn_data/hdfs/namenode</span><br><span class="line">$ sudo chmod 750 <span class="variable">$HADOOP_HOME</span>/yarn_data/hdfs/datanode</span><br></pre></td></tr></table></figure></p>
<p>Note: If we use existing users in the machine, then remember to replace the username and group name above. In fact, group name is not necessary.<br>      If we forget to create this directory or grant the correct ownerships or permissions, a java.io.IOException will be thrown out.</p>
<p>At last, edit the following files in Hadoop project directory:<br>For etc/hadoop/yarn-site.xml, adding following context between “<configuration>  </configuration>“ tag:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;mapreduce_shuffle&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;yarn.nodemanager.aux-services.mapreduce.shuffle.class&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure></p>
<p>For etc/hadoop/core-site.xml, adding following context between “<configuration> </configuration>“ tag:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;fs.default.name&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;hdfs://localhost:9000&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure></p>
<p>For etc/hadoop/mapred-site.xml, adding following context between “<configuration>  </configuration>“ tag:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">  &lt;name&gt;mapreduce.framework.name&lt;/name&gt;</span><br><span class="line">  &lt;value&gt;yarn&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure></p>
<p>For etc/hadoop/hdfs-site.xml, adding following context between “<configuration>  </configuration>“ tag:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.replication&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;1&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;file:/usr/<span class="built_in">local</span>/hadoop/yarn_data/hdfs/namenode&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br><span class="line"></span><br><span class="line">&lt;property&gt;</span><br><span class="line">    &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;</span><br><span class="line">    &lt;value&gt;file:/usr/<span class="built_in">local</span>/hadoop/yarn_data/hdfs/datanode&lt;/value&gt;</span><br><span class="line">&lt;/property&gt;</span><br></pre></td></tr></table></figure></p>
<hr>

<p>#####Formating HDFS via NameNode<br>Use the following commands to format the HDFS:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ /usr/<span class="built_in">local</span>/hadoop/bin/hadoop namenode -format</span><br></pre></td></tr></table></figure></p>
<p>The output is very long and the end of it looks like this:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">09/01/15 16:59:56 INFO namenode.FSNamesystem: fsOwner=hduser,hadoop</span><br><span class="line">09/01/15 16:59:56 INFO namenode.FSNamesystem: supergroup=supergroup</span><br><span class="line">09/01/15 16:59:56 INFO namenode.FSNamesystem: isPermissionEnabled=<span class="literal">true</span></span><br><span class="line">09/01/15 16:59:56 INFO common.Storage: Image file of size 96 saved <span class="keyword">in</span> 0 seconds.</span><br><span class="line">09/01/15 16:59:57 INFO common.Storage: Storage directory .../hadoop-hduser/dfs/name has been successfully formatted.</span><br><span class="line">09/01/15 16:59:57 INFO namenode.NameNode: SHUTDOWN_MSG:</span><br><span class="line">/************************************************************</span><br><span class="line">SHUTDOWN_MSG: Shutting down NameNode at ubuntu/127.0.1.1</span><br><span class="line">************************************************************/</span><br></pre></td></tr></table></figure></p>
<p>Now, everything is ready~ We can start the Hadoop system now~</p>
<hr>

<p>#####Starting Single-Node Cluster<br>Use the following commands:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ /usr/<span class="built_in">local</span>/hadoop/sbin/start-yarn.sh</span><br></pre></td></tr></table></figure></p>
<p>Now nodemanager and resourcemanager starts.</p>
<p>Then run these commands to start the rest of nodes:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ /usr/<span class="built_in">local</span>/hadoop/sbin/hadoop-daemon.sh start namenode</span><br><span class="line">$ /usr/<span class="built_in">local</span>/hadoop/sbin/hadoop-daemon.sh start datanode</span><br><span class="line">$ /usr/<span class="built_in">local</span>/hadoop/sbin/mr-jobhistory-daemon.sh start historyserver</span><br></pre></td></tr></table></figure></p>
<p>Now use “jps” command, the output should look like this:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ jps</span><br><span class="line">2085 ResourceManager</span><br><span class="line">2349 Jps</span><br><span class="line">1788 NodeManager</span><br><span class="line">1553 NameNode</span><br><span class="line">1788 DataNode</span><br><span class="line">1437 JobHistoryServer</span><br></pre></td></tr></table></figure></p>
<p>Go to this link:<br><a href="http://localhost:8088/" target="_blank" rel="external">http://localhost:8088/</a> ResourceManager</p>
<p>#####Stopping Single-Node Cluster<br>Use the following commands:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ /usr/<span class="built_in">local</span>/hadoop/sbin/stop-yarn.sh</span><br><span class="line">$ /usr/<span class="built_in">local</span>/hadoop/sbin/stop-dfs.sh</span><br></pre></td></tr></table></figure></p>
<p>Here is two scripts that can make things easier:<br>The script to start Hadoop-2 cluster:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span><br><span class="line"></span></span><br><span class="line">sh /usr/<span class="built_in">local</span>/hadoop/sbin/start-yarn.sh</span><br><span class="line">sh /usr/<span class="built_in">local</span>/hadoop/sbin/hadoop-daemon.sh start namenode</span><br><span class="line">sh /usr/<span class="built_in">local</span>/hadoop/sbin/hadoop-daemon.sh start datanode</span><br><span class="line">sh /usr/<span class="built_in">local</span>/hadoop/sbin/mr-jobhistory-daemon.sh start historyserver</span><br></pre></td></tr></table></figure></p>
<p>The script to stop Hadoop-2 cluster:<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sh /usr/<span class="built_in">local</span>/hadoop/sbin/stop-yarn.sh</span><br><span class="line">sh /usr/<span class="built_in">local</span>/hadoop/sbin/hadoop-daemon.sh stop namenode</span><br><span class="line">sh /usr/<span class="built_in">local</span>/hadoop/sbin/hadoop-daemon.sh stop datanode</span><br><span class="line">sh /usr/<span class="built_in">local</span>/hadoop/sbin/mr-jobhistory-daemon.sh stop historyserver</span><br></pre></td></tr></table></figure></p>
<p>This lazy guide is over. If you have any questions, just leave your comments on this blog. For more details, just go to the tutorial provided on the top of this blog.</p>

      
    </div>
    
    <footer>
        <div class="alignright">
          
          <a href='javascript:void(0)' class="share-link bdsharebuttonbox" data-cmd="more">Share</a>
        </div>
        
        
  
  <div class="tags">
    <a href="/tags/Cloud-Computing/">Cloud Computing</a>
  </div>

        <!-- partial('post/share') -->
      <div class="clearfix"></div>
    </footer>
  </div>
</article>







<nav id="pagination">
  
  <nav id="page-nav">
    <a class="extend prev" rel="prev" href="/page/6/">&laquo; Vorherige Seite</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/5/">5</a><a class="page-number" href="/page/6/">6</a><span class="page-number current">7</span><a class="page-number" href="/page/8/">8</a><a class="page-number" href="/page/9/">9</a><span class="space">&hellip;</span><a class="page-number" href="/page/13/">13</a><a class="extend next" rel="next" href="/page/8/">Nächste Seite &raquo;</a>
  </nav>

</nav>
</div></div>
    <aside id="sidebar" class="alignright">
  <div class="search">
  <form action="//google.com/search" method="get" accept-charset="utf-8">
    <input type="search" name="q" results="0" placeholder="Google Search">
    <input type="hidden" name="q" value="">
  </form>
</div>

<div class="search">
   <form class="search" action="/search/index.html" method="get" accept-charset="utf-8">
     <input type="search" id="search" class="st-default-search-input" style="height:40px" maxlength="20" placeholder="WebSite Search" />
     <input type="hidden" name="q" value="">
   </form>
</div>



  
  <div class="widget tag">
    <h3 class="title">Archive</h3>
    <div class="entry">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/03/">March 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/02/">February 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/01/">January 2016</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/12/">December 2015</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/11/">November 2015</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/10/">October 2015</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/09/">September 2015</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/08/">August 2015</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/07/">July 2015</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/06/">June 2015</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/05/">May 2015</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/02/">February 2015</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/01/">January 2015</a></li></ul>
    </div>
  </div>



  
<div class="widget tag">
  <h3 class="title">Tags</h3>
  <ul class="entry">
  
    <li><a href="/tags/Algorithm/">Algorithm</a><small>35</small></li>
  
    <li><a href="/tags/Android/">Android</a><small>1</small></li>
  
    <li><a href="/tags/Business-Model/">Business Model</a><small>1</small></li>
  
    <li><a href="/tags/C/">C++</a><small>2</small></li>
  
    <li><a href="/tags/Cloud-Computing/">Cloud Computing</a><small>18</small></li>
  
    <li><a href="/tags/Combinatorics/">Combinatorics</a><small>1</small></li>
  
    <li><a href="/tags/Data-Analysis/">Data Analysis</a><small>1</small></li>
  
    <li><a href="/tags/Database/">Database</a><small>3</small></li>
  
    <li><a href="/tags/Graph-Theory/">Graph Theory</a><small>1</small></li>
  
    <li><a href="/tags/IOS/">IOS</a><small>1</small></li>
  
    <li><a href="/tags/Interview-Summary/">Interview Summary</a><small>2</small></li>
  
    <li><a href="/tags/Java/">Java</a><small>7</small></li>
  
    <li><a href="/tags/Life/">Life</a><small>2</small></li>
  
    <li><a href="/tags/Life-Thoughts/">Life Thoughts</a><small>1</small></li>
  
    <li><a href="/tags/Linux/">Linux</a><small>10</small></li>
  
    <li><a href="/tags/Machine-Learning/">Machine Learning</a><small>9</small></li>
  
    <li><a href="/tags/Python/">Python</a><small>1</small></li>
  
    <li><a href="/tags/R/">R</a><small>1</small></li>
  
    <li><a href="/tags/System-Design/">System Design</a><small>7</small></li>
  
    <li><a href="/tags/Test/">Test</a><small>1</small></li>
  
    <li><a href="/tags/Tools/">Tools</a><small>3</small></li>
  
    <li><a href="/tags/Web/">Web</a><small>16</small></li>
  
  </ul>
</div>


  
<div class="widget tagcloud">
  <h3 class="title">Tag-Cloud</h3>
  <div class="entry">
    <a href="/tags/Algorithm/" style="font-size: 20px;">Algorithm</a> <a href="/tags/Android/" style="font-size: 10px;">Android</a> <a href="/tags/Business-Model/" style="font-size: 10px;">Business Model</a> <a href="/tags/C/" style="font-size: 11.25px;">C++</a> <a href="/tags/Cloud-Computing/" style="font-size: 18.75px;">Cloud Computing</a> <a href="/tags/Combinatorics/" style="font-size: 10px;">Combinatorics</a> <a href="/tags/Data-Analysis/" style="font-size: 10px;">Data Analysis</a> <a href="/tags/Database/" style="font-size: 12.5px;">Database</a> <a href="/tags/Graph-Theory/" style="font-size: 10px;">Graph Theory</a> <a href="/tags/IOS/" style="font-size: 10px;">IOS</a> <a href="/tags/Interview-Summary/" style="font-size: 11.25px;">Interview Summary</a> <a href="/tags/Java/" style="font-size: 13.75px;">Java</a> <a href="/tags/Life/" style="font-size: 11.25px;">Life</a> <a href="/tags/Life-Thoughts/" style="font-size: 10px;">Life Thoughts</a> <a href="/tags/Linux/" style="font-size: 16.25px;">Linux</a> <a href="/tags/Machine-Learning/" style="font-size: 15px;">Machine Learning</a> <a href="/tags/Python/" style="font-size: 10px;">Python</a> <a href="/tags/R/" style="font-size: 10px;">R</a> <a href="/tags/System-Design/" style="font-size: 13.75px;">System Design</a> <a href="/tags/Test/" style="font-size: 10px;">Test</a> <a href="/tags/Tools/" style="font-size: 12.5px;">Tools</a> <a href="/tags/Web/" style="font-size: 17.5px;">Web</a>
  </div>
</div>


  

  <div class="widget tag">
  <h3 class="title">Friend Links</h3>
  <ul class="entry">
    <li><a href="http://blog.haosdent.me/"  target="_blank">Haosong Huang's Blog</a></li>
  </ul>
</div>


  
<div class="widget tag">
  <h3 class="title">Recent Posts</h3>
  <ul class="entry">
    
      <li>
        <a href="/2016/03/30/Redis-QuickStart/">Redis QuickStart</a>
      </li>
    
      <li>
        <a href="/2016/03/27/CSS-Pattern-List/">CSS Pattern List</a>
      </li>
    
      <li>
        <a href="/2016/03/25/MongoDB-Quick-Start-on-Mac/">MongoDB Quick Start on Mac</a>
      </li>
    
      <li>
        <a href="/2016/03/20/Hexo-Blog-简明教程-III/">Hexo Blog 简明教程 III</a>
      </li>
    
      <li>
        <a href="/2016/03/20/Hexo-Blog-简明教程-II/">Hexo Blog 简明教程 II</a>
      </li>
    
  </ul>
</div>



  <div id="recentcomments" class="widget tag">
    <h3 class="title">Recent Comments</h3>
    <div class="entry">
      <div id="recentcomments" class="dsq-widget">
        <script type="text/javascript" src="http://yular.disqus.com/recent_comments_widget.js?num_items=10&hide_avatars=1&avatar_size=32&excerpt_length=100&hide_mods=0"></script>
      </div>
    </div>
</div>


  <div class="widget tag">
  <script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>
  <h3 class="title">Statics</h3>
  <ul class="entry">   
    <li><span id="busuanzi_container_site_pv">Total Visits: <span id="busuanzi_value_site_pv"></span></span></li>
    <li><span id="busuanzi_container_site_uv">Total Visitors: <span id="busuanzi_value_site_uv"></span></span></li>
  </div>
</div>

</aside>
    <div class="clearfix"></div>
  </div>
  <footer id="footer" class="inner"><div class="alignleft">
  <p>
  
  &copy; 2016 BaiChuan Yang
  
  All rights reserved.</p>
  <p>Powered by <a href="http://hexo.io/" target="_blank">Hexo</a></p>
</div>
<div class="alignright">
   <div style="font-family: FontAwesome;font-size: 20px;">
     <a href="http://weibo.com/u/5854007817?is_all=1" title="weibo" target="_blank"><img src="/css/images/weibo-social-logo.png"></a>&nbsp;
     <a href="https://www.facebook.com/johnson.green.338" title="Facebook" target="_blank"><img src="/css/images/facebook-logo.png"></a>&nbsp;
     <a href="https://twitter.com/JohnsonGreen5" title="twitter" target="_blank"><img src="/css/images/twitter-logo.png"></a>&nbsp;
     <a href="https://www.linkedin.com/in/baichuan-yang-6b7b6579" title="LinkedIn" target="_blank"><img src="/css/images/linkedin-logo.png"></a>&nbsp;
     <a href="https://github.com/yular" title="GitHub" target="_blank"><img src="/css/images/github-sign.png"></a>&nbsp;
     <a href="https://plus.google.com/u/0/+BaichuanYANG/" title="Google+" target="_blank"><img src="/css/images/social-google-plus-square-button.png"></a>
  </div>
</div>
<div class="clearfix"></div>

<script>window._bd_share_config={"common":{"bdSnsKey":{},"bdText":"","bdMini":"1","bdMiniList":false,"bdPic":"","bdStyle":"2","bdSize":"16"},"share":{}};with(document)0[(getElementsByTagName('head')[0]||body).appendChild(createElement('script')).src='http://bdimg.share.baidu.com/static/api/js/share.js?v=89860593.js?cdnversion='+~(-new Date()/36e5)];</script>
</footer>
  <script src="/js/jquery-1.12.1.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>


<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script>


    <script type="text/javascript">
    var disqus_shortname = 'yular';

    (function(){
      var dsq = document.createElement('script');
      dsq.type = 'text/javascript';
      dsq.async = true;
      dsq.src = '//' + disqus_shortname + '.disqus.com/count.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
    </script>

<div id="totop" style="position:fixed;bottom:150px;right:50px;cursor: pointer;">
<a title="backtotop"><img src="/imgs/scrollup.png"/></a>
</div>

<script src="/js/totop.js"></script>
<div id='bg'></div>

</body>
</html>